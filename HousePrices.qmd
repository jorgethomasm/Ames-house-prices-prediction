---
title: "Prediction of House Prices in Ames"
subtitle: "My approach to advance regression with visual analytics techniques." # only for html output
author: "Jorge A. Thomas"
date: "`r Sys.Date()`"
format:    
    html:
      self-contained: true
      code-fold: true
      df-print: tibble
      code-summary: "Show the code"
      grid: 
        margin-width: 350px
execute: 
  echo: fenced
reference-location: margin # margin
citation-location: document
bibliography: HousePrices.bib
# Template: https://quarto-dev.github.io/quarto-gallery/page-layout/tufte.html
---

```{r}
#| label: setup
#| message: false
#| echo: false

library(tidyverse) # ETL and EDA tools
source("./tools/jthom_functions.r")
theme_set(jthom_ggtheme)
```

::: {#fig-intro layout-ncol=2}

![Houses](./imgs/ames_gai_16x9.jpeg){width=100%}

![Location](./imgs/Ames_map.png){width=100%}

Ames, Iowa - USA.
:::

# Introduction

In this classic Kaggle dataset [@house-prices-advanced-regression-techniques] you'll follow my workflow developing pipelines on the ETL phase of the DS cycle, as well as a tidy approach on the EDA substantialy supported on Visual Analytics. I'll be feeding some tips along the analysis.

The Ames House dataset was prepared to improve on the older classic Boston Houses dataset and, given its open competition nature, it comprises two files:

1. One file contains features and labels (or what's the same predictors and response). Here this is the *training dataset*. It's all I have to split the *Data Budget*.

2. Another file contains only features (predictors) to make predictions for the final submissions. Here this is the *test dataset*.

The goal of the competition is to achieve minimum RMSE.

I will keep updating this notebook, making improvements and reporting the rank obtained with my submitted predictions.

# PHASE I: ETL / EDA

## Extract Data

I checked beforehands that there are no missing values, here `NA`, in the target variable `SalePrice`. 
Therefore, I will write a pipeline to read and concatenate both datasets (bind rows), adding and extra column `dataset` to label as "train" and "test" for further easy splitting[^1] (subset or filter).

[^1]: Tip: The whole Feature Transformation pipeline most be always the same for all predictors in both datasets.

```{r}
#| label: Load Data
#| warning: false

ames_train_raw <- read_csv("./data/raw/train.csv") # Train, validattion and test dataset
print("Dimensions of training dataset")
dim(ames_train_raw)

ames_test_raw <- read_csv("./data/raw/test.csv")  # Features for submission dataset
print("Dimensions of test dataset containing only Feats.")
dim(ames_test_raw) 

# Add Target column with NA so both DFs can be concatenated:.id
ames_test_raw <- ames_test_raw |> mutate(SalePrice = NA)

# Binding and adding identifier column "dataset" 
ames_all <- bind_rows(list(train = ames_train_raw, test = ames_test_raw), .id = "dataset")

print("Available variables:")
names(ames_all)
```

In order to organise my **Data Budget** I count on the **train dataset** with 1460 Observations of 79 predictors (one column is only an `Id` per house) and the Response, which is the `SalePrice` of the houses at the end of the list above.

Note that `Id` and the just added `dataset` columns are not predictors. Hence, there are **79 features** to play  with. Also rememeber that the number of features for modelling will vary. Some will be discarded and some will be created along the analysis.

I'll get rid of the `Id` column:
```{r}
#| label: Remove Id

ames_all$Id <- NULL
```

## Impute Missing Values

First things first, read the full data description[^2]. The manifest is available [here](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data). There you'll find that for several columns missing values `NA` means actually *"None"*. The physical absence of a determined feature in a house is a category exposing the lack of such quality that can have a significant impact on the response `SalePrice`. Later it is most probably that binary features indicating the existance of some installations should be created.

Therefore, I will fill the empty `NA` fields of the indicated columns of both datasets with the string *"None"*.

[^2]: Tip: **print a copy**, make notes and study it. This is the first step to get into domain knowledge, in this case Real Estate, for later *Feature Engineering*.

```{r}
#| label: easy replace_na

cols_NA_to_none <- list(
  Alley = "None",
  BsmtQual = "None", BsmtCond = "None", BsmtExposure = "None", BsmtFinType1 = "None", BsmtFinType2 = "None", 
  FireplaceQu = "None", 
  GarageType = "None", GarageFinish = "None", GarageQual = "None", GarageCond = "None", 
  PoolQC = "None",
  Fence = "None", 
  MiscFeature = "None")

ames_all <- ames_all |>
  replace_na(cols_NA_to_none)   
```

One of the early and recurrent steps of the EDA is to check the **completeness of data**. Let's search for missing values, after filling indicated fields[^3]. 
For this case I wrote the function `count_na()` that generates the table displayed on the right margin.

[^3]: Tip: **write a function to quantify missing values** depending on the language and labelling system used. 

```{r}
#| label: Counting NAs
#| code-fold: false
#| column: margin

# Remaining NA count leaving out target SalePrice
ames_all |> 
  select(-SalePrice) |>
  count_na() |>  
  knitr::kable(caption = 'Ames dataset')
```

I'll fill the remaining missing values as follow:

- The `LotFrontage` column refers to the linear feet of street connected to the house. This feature is not well documented and the missing percentage related to other variables makes it not only unreliable, but very low in variance. Therefore, I will delete the feature.

- Everytime a Garage doesn't exist, i.e., `GarageType = "None"`, there is the corresponding missing value in Garage Year Built `GarageYrBlt = NA`. I will **engineer a new feature** called `GarageNew` with three ordinal categories: None, No, Yes. This based on the delta of `YearBuilt - GarageYrBlt`; I expect that given the house price, the algorithm will learn that "None" is worse than "No" and so on. Then I will remove the `GarageYrBlt` predictor.

- For the rest of variables with a 1 % or less missing values `NA`, I'll calculate the **median** (if numerical) and the **mode** (if string) in order to fill them with it.

Here's my pipeline for the whole dataset:

```{r}
#| label: terminating NAs

# "replace_na_with_median" is a custom function

ames_all <- ames_all |>
  mutate(LotFrontage = NULL) |> # Removing LotFrontage
  mutate(GarageNew = if_else(YearBuilt - GarageYrBlt > 0, "Yes", "No")) |> # New Feat.
  replace_na(list(GarageNew = "None")) |>
  mutate(GarageNew = factor(GarageNew, levels = c("None", "No", "Yes"))) |> # 3 levels
  mutate(GarageYrBlt = NULL) |> # Removing old Feat.
  mutate_if(is.numeric, replace_na_with_median)
```

Let's get a list with the mode of each remaining columns containing missing values `NA`.

```{r }
#| label: Mode for NAs

# Get the mode for reamaining columns with NAs:
# "find_mode()" is a custom function.

# Good, old-fashioned code: apply(ames_all, 2, find_mode)

list_na_mode <- ames_all |> 
  select(MasVnrType, MasVnrArea, MSZoning, Electrical, Utilities,	BsmtFullBath,	BsmtHalfBath,	Functional,	Exterior1st,	Exterior2nd,	BsmtFinSF1,	BsmtFinSF2,	BsmtUnfSF,	TotalBsmtSF,	KitchenQual,GarageCars,	GarageArea,	SaleType) |>
  map(find_mode)

# map returns a list 

# Replace with the created named-lists
ames_all <- ames_all |>
  replace_na(list_na_mode) 

# Sanity check of missing values:
print("Full Ames dataset (train and test)")
ames_all |>
  select(-SalePrice) |>
  count_na()
```

**"The data is complete!"** Let's think about predictors.

## Feature Engineering

I have already started with the creation of a new predictor in the previous step, this to substitute the problematic variable `GarageYrBlt` that had a lot of missing values.

Feature creation and transformations are not sequential, i.e., this is not the only step where *Feature Engineering* is applied. 
Think about the next *modelling phase*, where you want to reduce features, e.g., where new Principal Components are the new aggregators of original features.

In this part I will establish which variables are categorical and numerical; this is not always as obvious as it seems[^4].

[^4]: Tip: integer variables like calendar *Years* can be treated as categories for the analysis.

The first easy thing that comes to mind is to add the **total area of the property** as a new column named `TotalAreaSF`; SF means *Squared Feet*.

After that, I check the [data documentation](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data) to see which variables can be thought as categoricals (factors); this can be tedeous if Real Estate is not your domain of expertise. 

After 1.5 hours of reading, googling, understanding other notebooks and deliberating (yes, it was tedeous), I can summarise four types of ways to engineer new features depending on the nature of the variables:

1. Aggregation to a total of **continous-numerical** surface area (Square Feet), e.g. new `TotalInteriorArea` Feat. summing basement and floors, etc. Same for a new `TotalExteriorArea`. Then deleting the addends variables.

2. Aggregation to a total of **numerical counts** of an available installation of a determined type, e.g. new `TotalBaths`. Then deleting the addends.

3. Categorisation with ascending quality levels of the originally numerical variables `OverallQual` and `OverallCond`. 

4. Creation of new **binary** features that state if a determined installation exists or doesn't.

Here's the code that complies with the four previous steps:

```{r}
#| label: Feature Engineering

# --- Total Aggregations ----
ames_all <- ames_all |>

  # Continuous numerical ----
  # NEW TotalInteriorArea
  mutate(TotalInteriorArea = BsmtFinSF1 + BsmtFinSF2 + `1stFlrSF` + `2ndFlrSF`) |>
  select(-c(BsmtFinSF1, BsmtFinSF2, `1stFlrSF`))|> # Bye bye...

  # NEW TotalExteriorArea
  mutate(TotalExteriorArea = WoodDeckSF + OpenPorchSF + EnclosedPorch + `3SsnPorch` + ScreenPorch) |>
  select(-c(WoodDeckSF, OpenPorchSF, EnclosedPorch, `3SsnPorch`, ScreenPorch)) |># Bye bye...

  # Counting numerical ----
  # NEW TotalBaths
  mutate(TotalBaths = BsmtFullBath + 0.5 * BsmtHalfBath + FullBath + 0.5 * HalfBath) |> 
  select(-c(BsmtFullBath, BsmtHalfBath, FullBath, HalfBath)) # Bye bye...


# ---- Ordered Categorical Features ----
ames_all <- ames_all |>
  mutate(OverallQual = factor(OverallQual)) |>
  mutate(OverallCond = factor(OverallCond))  # Check level orders 1, ..., 10 (BEST)


# ---- Binary Features ----
# Does the installation exist? 

ames_all <- ames_all |>
  # CentralAir
  mutate(CentralAir = if_else(CentralAir == "N", "No", "Yes")) |>
  mutate(CentralAir = fct_relevel(CentralAir, "No", "Yes"))|>

  # NEW IsRemodelled (it will replace YearRemodAdd)
  mutate(IsRemodelled = if_else(YearRemodAdd - YearBuilt > 0, "Yes", "No")) |>
  mutate(IsRemodelled = factor(IsRemodelled, levels = c("No", "Yes"))) |>
  select(-YearRemodAdd) |> # Bye YearRemodAdd

  # NEW ExistPool
  mutate(ExistPool = if_else(PoolArea == 0, "No", "Yes")) |>
  mutate(ExistPool = fct_relevel(ExistPool, "No", "Yes"))|>

  # NEW ExistGarage
  mutate(ExistGarage = if_else(GarageArea == 0, "No", "Yes")) |>
  mutate(ExistGarage = fct_relevel(ExistGarage, "No", "Yes"))|>

  # NEW ExistBsmt
  mutate(ExistBsmt = if_else(TotalBsmtSF == 0, "No", "Yes")) |>
  mutate(ExistBsmt = fct_relevel(ExistBsmt, "No", "Yes"))|>

  # NEW Exist2ndFloor
  mutate(Exist2ndFloor = if_else(`2ndFlrSF` == 0, "No", "Yes")) |>
  select(-`2ndFlrSF`) |> # Bye, bye... 
  mutate(Exist2ndFloor = fct_relevel(Exist2ndFloor, "No", "Yes")) |>

  # NEW ExistFireplace
  mutate(ExistFireplace = if_else(Fireplaces == 0, "No", "Yes")) |>
  mutate(ExistFireplace = fct_relevel(ExistFireplace, "No", "Yes"))


# ---- The rest are factors ----
# I'm going to assume that the rest are Categorical variables 

ames_all <- ames_all |>
  mutate(across(where(is.character), factor))

# ---- Numerical Features ----

# BedroomabvGr (count) left numerical 
# Kitchens (count) left numerical 
# TotRmsAbvGrd (count) left numerical
# Fireplaces (count) left numerical
# GarageCars (count) left numerical
# GarageArea (continous) left numerical 
# MiscVal left numerical 
# MasVnrArea (continous) left numeric


# ---- Remove 'LowQualFinSF' ----

# Low quality finished square feet (all floors)
# Most of the values are 0 -> almost 0 variance. 
ames_all$LowQualFinSF <- NULL

```

Note that I replaced `YearRemodAdd` to a simpler binary `IsRemodelled` variable, similar to what I did with the new `GarageNew` column.

OK! Let's move on. 

### Response behaviour analysis

```{r}
#| label: Response behaviour
#| message: false
#| warning: false
#| fig-show: hold
#| fig-width: 12
#| fig-height: 6
#| fig-column: page-right
#| layout-ncol: 2
#| fig-cap: 
#|   - "The response variable is clearly not well-bahaved. In order to achieve better predictions, a transformation of this variable in needed."
#| fig-subcap: 
#|   - "Histogram of Sale Prices"
#|   - "Q-Q Plot of Sale Prices"
#| cap-location: margin

ames_all |>
  filter(dataset == "train") |>
  ggplot(aes(x = SalePrice/1000)) +  
  geom_histogram(bins = 50, color = "seagreen", fill = "seagreen", alpha = 0.5) +
  scale_x_continuous(breaks = seq(0, 800, 50), labels = scales::comma) +  
  labs(x = "Sale Price ['000 $]")

ames_all |>
  filter(dataset == "train") |> 
  ggplot(aes(sample = SalePrice/1000)) + 
  stat_qq(color = "seagreen", alpha = 0.5) + 
  stat_qq_line(color = "seagreen") + 
  scale_y_continuous(breaks = seq(0, 800, 50), labels = scales::comma) +
  labs(y = "Sale Price\n['000 $]",
       x = "Theoretical Quantiles (Norm. Dist.)")

```


#### Data Transformations

The moment the first data transformation is performed, we start to loose interpretability very quickly. 
Nowadays, the most accurate predictions need more than one transformation in order to work best[^5]. 

[^5]: Tip: Forget about lineaerity and interpretability if you want the most accurate results.  

If understanding and interpretability is your first goal, then start with a parametric linear model.

In my experience, processes that have to do with *money*, e.g., sale prices, costs of products, salaries, they are most of the time Log-Normal. 
Rarely is something free, so you don't have zeros; think about the top 1% of reach people, or anything that becomes exotic or **premium** the higher the ammount of money is involved. These are long and sparsed tails.

Logarithmic transformations work when there are few large values, like in this case, there are only a few expensive hauses. The logarithm scale will shrink that right tail[^6], making the distribution of the values more normal-like.

[^6]: Tip: think of a **Logarithmic transformation** like pressing an **accordeon** only from your right arm.


### Plots 

It's PLOT TIME!

#### Pearson's Correlograms

Although **nothing is linear**, is good to have an idea of correlation between features; after doing previous steps, it's obvious there are correlations.

```{r}
#| label: Inspect linear correlations
#| fig-cap: write something...
#| warning: false
#| message: false

library(corrplot)

ames_all |>
  select(where(is.numeric)) |>  
  cor(method = "pearson") |>
  corrplot(type = "lower", order="hclust", diag = TRUE, 
  tl.col="black", tl.cex = 0.7, addCoef.col = 'black', number.cex = 0.6)





# m_cor_num <- cor(na.omit(ames_all))
# m_cor_num_ordered <- m_cor_num[order(m_cor_num[, 36]), ]






```



# PHASE 2: MODELLING

&emsp; *"This is where the fun begins."*  – H. Solo

## Reference Model

## Model Selection

## Margin Figures

Images and graphics play an integral role in Tufte's work. To place figures in the margin you can use the **Quarto** chunk option `column: margin`. For example:

```{r}
#| label: fig-margin
#| fig-cap: "MPG vs horsepower, colored by transmission."
#| column: margin
#| message: false
library(ggplot2)
mtcars2 <- mtcars
mtcars2$am <- factor(
  mtcars$am, labels = c('automatic', 'manual')
)
ggplot(mtcars2, aes(hp, mpg, color = am)) +
  geom_point() + geom_smooth() +
  theme(legend.position = 'bottom')
```

Note the use of the `fig-cap` chunk option to provide a figure caption. You can adjust the proportions of figures using the `fig-width` and `fig-height` chunk options. These are specified in inches, and will be automatically scaled down to fit within the handout margin.

## Arbitrary Margin Content

You can include anything in the margin by places the class `.column-margin` on the element. See an example on the right about the first fundamental theorem of calculus.

::: column-margin
We know from *the first fundamental theorem of calculus* that for $x$ in $[a, b]$:

$$\frac{d}{dx}\left( \int_{a}^{x} f(u)\,du\right)=f(x).$$
:::

## Full Width Figures

You can arrange for figures to span across the entire page by using the chunk option `fig-column: page-right`.

```{r}
#| label: fig-fullwidth
#| fig-cap: "A full width figure."
#| fig-width: 11
#| fig-height: 3
#| fig-column: page-right
#| warning: false
ggplot(diamonds, aes(carat, price)) + geom_smooth() +
  facet_grid(~ cut)
```

Other chunk options related to figures can still be used, such as `fig-width`, `fig-cap`, and so on. For full width figures, usually `fig-width` is large and `fig-height` is small. In the above example, the plot size is $11 \times 3$.

## Arbitrary Full Width Content

Any content can span to the full width of the page, simply place the element in a `div` and add the class `column-page-right`. For example, the following code will display its contents as full width.

``` md
::: {.fullwidth}
Any _full width_ content here.
:::
```

Below is an example:

::: column-page-right
*R is free software and comes with ABSOLUTELY NO WARRANTY.* You are welcome to redistribute it under the terms of the GNU General Public License versions 2 or 3. For more information about these matters see <https://www.gnu.org/licenses/>.
:::

## Main Column Figures

Besides margin and full width figures, you can of course also include figures constrained to the main column. This is the default type of figures in the LaTeX/HTML output.

```{r}
#| label: fig-main
#| fig-cap: "A figure in the main column."
ggplot(diamonds, aes(cut, price)) + geom_boxplot()
```

## Margin Captions

When you include a figure constrained to the main column, you can choose to place the figure's caption in the margin by using the `cap-location` chunk option. For example:

```{r}
#| label: fig-main-margin-cap
#| fig-cap: "A figure with a longer caption. The figure appears in the main column, but the caption is placed in the margin. Captions can even contain elements like a citation such as @R-base."
#| cap-location: margin
ggplot(diamonds, aes(cut, price)) + geom_boxplot()
```

# Sidenotes

One of the most prominent and distinctive features of this style is the extensive use of sidenotes. There is a wide margin to provide ample room for sidenotes and small figures. Any use of a footnote will automatically be converted to a sidenote.

[This is a span that has the class `column-margin` which places it in the margin without the sidenote mark.]{.column-margin} If you'd like to place ancillary information in the margin without the sidenote mark (the superscript number), you can use apply the `column-margin` class to the element.

# References

References can be displayed as margin notes for HTML output. For example, we can cite R here [@R-base].

::: {.callout-note appearance="simple"}
This feature depends upon `link-citations` to locate and place references in the margin. This is enabled by default, but if you disable `link-citations` then references in the HTML output will be placed at the end of the output document as they normally are.
:::

# Responsiveness

The HTML page layout is responsive- as the page width shrinks, elements will automatically adjust their position. Elements that appear in the margins will move inline with the content and elements that span the body and margin will automatically span only the body.

# More Examples

The rest of this document consists of a few test cases to make sure everything still works well in slightly more complicated scenarios. First we generate two plots in one figure environment with the chunk option `fig-show: hold`:

```{r}
#| label: fig-two-together
#| fig-cap: "Two plots in one figure environment."
#| fig-show: hold
#| warning: false
#| cap-location: margin
p <- ggplot(mtcars2, aes(hp, mpg, color = am)) +
  geom_point()
p
p + geom_smooth()
```

Then two plots in separate figure environments (the code is identical to the previous code chunk, but the chunk option is the default `fig-show: asis` now):

```{r fig-two-separate, ref.label='fig-two-together', fig.cap=sprintf("Two plots in separate figure environments (the %s plot).", c("first", "second")), message=FALSE}
#| cap-location: margin
```

You may have noticed that the two figures have different captions, and that is because we used a character vector of length 2 for the chunk option `fig.cap` (something like `fig.cap = c('first plot', 'second plot')`).

::: {.callout-tip}
## Using R within Chunk Options
If you wish to use raw R expressions as part of the chunk options (like above), then you need to define those in the `tag=value` format within the curly brackets `{r label, tag=value}` instead of the `tag: value` YAML syntax on a new line starting with the hashpipe `#|`. The former approach is documented on [knitr's website](https://yihui.org/knitr/options/) while the latter is explained in [Quarto's documentation](https://quarto.org/docs/reference/cells/cells-knitr.html).
:::

Next we show multiple plots in margin figures. Similarly, two plots in the same figure environment in the margin:

```{r}
#| label: fig-margin-together
#| fig-cap: "Two plots in one figure environment in the margin."
#| fig-width: 3.5
#| fig-height: 2
#| fig-show: hold
#| column: margin
#| warning: false
#| echo: false
p
p + geom_smooth(method = 'lm')
```

Then two plots from the same code chunk placed in different figure environments:

```{r}
#| echo: false
knitr::kable(head(iris[,c(1,2,3,4)], 13))
```

```{r}
#| label: fig-margin-separate-a
#| fig-cap: "Two plots in separate figure environments in the margin"
#| fig-width: 3.5
#| fig-height: 2
#| column: margin
#| warning: false
#| echo: false
p
p + geom_smooth(method = 'lm')
```

```{r}
#| echo: false
knitr::kable(head(iris[,c(1,2,3,4)], 11))
```

We blended some tables in the above code chunk only as *placeholders* to make sure there is enough vertical space among the margin figures, otherwise they will be stacked tightly together. For a practical document, you should not insert too many margin figures consecutively and make the margin crowded.

You do not have to assign captions to figures. We show three figures with no captions below in the margin, in the main column, and in full width, respectively.

```{r}
#| fig-width: 3.5
#| fig-height: 2
#| column: margin
# a boxplot of weight vs transmission; this figure
# will be placed in the margin
ggplot(mtcars2, aes(am, wt)) + geom_boxplot() +
  coord_flip()
```

```{r}
#| warning: false
# a figure in the main column
p <- ggplot(mtcars, aes(wt, hp)) + geom_point()
p
```

```{r}
#| fig-width: 11
#| fig-height: 4
#| column: page-right
#| warning: false
# a fullwidth figure
p + geom_smooth(method = 'lm') + facet_grid(~ gear)
```

# Some Notes on Page Layout

To see the Quarto markdown source of this example document, you may follow [this link to Github](https://raw.githubusercontent.com/quarto-dev/quarto-gallery/main/page-layout/tufte.qmd).