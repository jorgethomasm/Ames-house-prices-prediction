[
  {
    "objectID": "HousePrices.html",
    "href": "HousePrices.html",
    "title": "Prediction of House Prices in Ames",
    "section": "",
    "text": "Houses\n\n\n\n\n\n\n\nLocation\n\n\n\n\nFigure 1: Ames, Iowa - USA."
  },
  {
    "objectID": "HousePrices.html#margin-figures",
    "href": "HousePrices.html#margin-figures",
    "title": "Prediction of House Prices in Ames",
    "section": "Margin Figures",
    "text": "Margin Figures\nImages and graphics play an integral role in Tufte’s work. To place figures in the margin you can use the Quarto chunk option column: margin. For example:\n\n\nCode\n```{r}\n#| label: fig-margin\n#| fig-cap: \"MPG vs horsepower, colored by transmission.\"\n#| column: margin\n#| message: false\nlibrary(ggplot2)\nmtcars2 &lt;- mtcars\nmtcars2$am &lt;- factor(\n  mtcars$am, labels = c('automatic', 'manual')\n)\nggplot(mtcars2, aes(hp, mpg, color = am)) +\n  geom_point() + geom_smooth() +\n  theme(legend.position = 'bottom')\n```\n\n\n\n\n\n\nFigure 10: MPG vs horsepower, colored by transmission.\n\n\n\nNote the use of the fig-cap chunk option to provide a figure caption. You can adjust the proportions of figures using the fig-width and fig-height chunk options. These are specified in inches, and will be automatically scaled down to fit within the handout margin."
  },
  {
    "objectID": "HousePrices.html#arbitrary-margin-content",
    "href": "HousePrices.html#arbitrary-margin-content",
    "title": "Prediction of House Prices in Ames",
    "section": "Arbitrary Margin Content",
    "text": "Arbitrary Margin Content\nYou can include anything in the margin by places the class .column-margin on the element. See an example on the right about the first fundamental theorem of calculus.\n\n\nWe know from the first fundamental theorem of calculus that for \\(x\\) in \\([a, b]\\):\n\\[\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).\\]"
  },
  {
    "objectID": "HousePrices.html#full-width-figures",
    "href": "HousePrices.html#full-width-figures",
    "title": "Prediction of House Prices in Ames",
    "section": "Full Width Figures",
    "text": "Full Width Figures\nYou can arrange for figures to span across the entire page by using the chunk option fig-column: page-right.\n\n\nCode\n```{r}\n#| label: fig-fullwidth\n#| fig-cap: \"A full width figure.\"\n#| fig-width: 11\n#| fig-height: 3\n#| fig-column: page-right\n#| warning: false\nggplot(diamonds, aes(carat, price)) + geom_smooth() +\n  facet_grid(~ cut)\n```\n\n\n\n\n\nFigure 12: A full width figure.\n\n\n\n\nOther chunk options related to figures can still be used, such as fig-width, fig-cap, and so on. For full width figures, usually fig-width is large and fig-height is small. In the above example, the plot size is \\(11 \\times 3\\)."
  },
  {
    "objectID": "HousePrices.html#arbitrary-full-width-content",
    "href": "HousePrices.html#arbitrary-full-width-content",
    "title": "Prediction of House Prices in Ames",
    "section": "Arbitrary Full Width Content",
    "text": "Arbitrary Full Width Content\nAny content can span to the full width of the page, simply place the element in a div and add the class column-page-right. For example, the following code will display its contents as full width.\n::: {.fullwidth}\nAny _full width_ content here.\n:::\nBelow is an example:\n\nR is free software and comes with ABSOLUTELY NO WARRANTY. You are welcome to redistribute it under the terms of the GNU General Public License versions 2 or 3. For more information about these matters see https://www.gnu.org/licenses/."
  },
  {
    "objectID": "HousePrices.html#main-column-figures",
    "href": "HousePrices.html#main-column-figures",
    "title": "Prediction of House Prices in Ames",
    "section": "Main Column Figures",
    "text": "Main Column Figures\nBesides margin and full width figures, you can of course also include figures constrained to the main column. This is the default type of figures in the LaTeX/HTML output.\n\n\nCode\n```{r}\n#| label: fig-main\n#| fig-cap: \"A figure in the main column.\"\nggplot(diamonds, aes(cut, price)) + geom_boxplot()\n```\n\n\n\n\n\nFigure 11: A figure in the main column."
  },
  {
    "objectID": "HousePrices.html#margin-captions",
    "href": "HousePrices.html#margin-captions",
    "title": "Prediction of House Prices in Ames",
    "section": "Margin Captions",
    "text": "Margin Captions\nWhen you include a figure constrained to the main column, you can choose to place the figure’s caption in the margin by using the cap-location chunk option. For example:\n\n\nCode\n```{r}\n#| label: fig-main-margin-cap\n#| fig-cap: \"A figure with a longer caption. The figure appears in the main column, but the caption is placed in the margin. Captions can even contain elements like a citation such as @R-base.\"\n#| cap-location: margin\nggplot(diamonds, aes(cut, price)) + geom_boxplot()\n```\n\n\n\n\n\nFigure 13: A figure with a longer caption. The figure appears in the main column, but the caption is placed in the margin. Captions can even contain elements like a citation such as R Core Team (2023)."
  },
  {
    "objectID": "Tufte_template_instructions.html",
    "href": "Tufte_template_instructions.html",
    "title": "Prediction of House Prices in Ames, Iowa",
    "section": "",
    "text": "This document demonstrates the use of a number of advanced page layout features to produce an attractive and usable document inspired by the Tufte handout style and the use of Tufte’s styles in RMarkdown documents. The Tufte handout style is a style that Edward Tufte uses in his books and handouts. Tufte’s style is known for its extensive use of sidenotes, tight integration of graphics with text, and well-set typography. Quarto1 supports most of the layout techniques that are used in the Tufte handout style for both HTML and LaTeX/PDF output.1 To learn more, you can read more about Quarto or visit Quarto’s Github repository.\n---\ntitle: \"An Example Using the Tufte Style\"\nauthor: \"John Smith\"\nformat:\n  html:\n    grid:\n1      margin-width: 350px\n  pdf: default\n2reference-location: margin\ncitation-location: margin\n---\n\n1\n\nIncreases the width of the margin to make more room for sidenotes and margin figures (HTML only).\n\n2\n\nPlaces footnotes and cited sources in the margin. Other layout options (for example placing a figure in the margin) will be set per element in examples below.\n\n\nThese layout features are designed with two important goals in mind:\n\nTo produce both PDF and HTML output with similar styles from the same Quarto document;\nTo provide simple syntax to write elements of the Tufte style such as side notes and margin figures. If you’d like a figure placed in the margin, just set the option fig-column: margin for your code chunk, and we will take care of the details for you2.\n\n2 You never need to think about \\begin{marginfigure} or &lt;span class=\"marginfigure\"&gt;; the LaTeX and HTML code under the hood may be complicated, but you never need to learn or write such code.If you have any feature requests or find bugs in these capabilities, please do not hesitate to file them to https://github.com/quarto-dev/quarto-cli/issues."
  },
  {
    "objectID": "Tufte_template_instructions.html#margin-figures",
    "href": "Tufte_template_instructions.html#margin-figures",
    "title": "Prediction of House Prices in Ames, Iowa",
    "section": "Margin Figures",
    "text": "Margin Figures\nImages and graphics play an integral role in Tufte’s work. To place figures in the margin you can use the Quarto chunk option column: margin. For example:\n\n\nCode\n```{r}\n#| label: fig-margin\n#| fig-cap: \"MPG vs horsepower, colored by transmission.\"\n#| column: margin\n#| message: false\nlibrary(ggplot2)\nmtcars2 &lt;- mtcars\nmtcars2$am &lt;- factor(\n  mtcars$am, labels = c('automatic', 'manual')\n)\nggplot(mtcars2, aes(hp, mpg, color = am)) +\n  geom_point() + geom_smooth() +\n  theme(legend.position = 'bottom')\n```\n\n\n\n\n\n\nFigure 1: MPG vs horsepower, colored by transmission.\n\n\n\nNote the use of the fig-cap chunk option to provide a figure caption. You can adjust the proportions of figures using the fig-width and fig-height chunk options. These are specified in inches, and will be automatically scaled down to fit within the handout margin."
  },
  {
    "objectID": "Tufte_template_instructions.html#arbitrary-margin-content",
    "href": "Tufte_template_instructions.html#arbitrary-margin-content",
    "title": "Prediction of House Prices in Ames, Iowa",
    "section": "Arbitrary Margin Content",
    "text": "Arbitrary Margin Content\nYou can include anything in the margin by places the class .column-margin on the element. See an example on the right about the first fundamental theorem of calculus.\n\n\nWe know from the first fundamental theorem of calculus that for \\(x\\) in \\([a, b]\\):\n\\[\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).\\]"
  },
  {
    "objectID": "Tufte_template_instructions.html#full-width-figures",
    "href": "Tufte_template_instructions.html#full-width-figures",
    "title": "Prediction of House Prices in Ames, Iowa",
    "section": "Full Width Figures",
    "text": "Full Width Figures\nYou can arrange for figures to span across the entire page by using the chunk option fig-column: page-right.\n\n\nCode\n```{r}\n#| label: fig-fullwidth\n#| fig-cap: \"A full width figure.\"\n#| fig-width: 11\n#| fig-height: 3\n#| fig-column: page-right\n#| warning: false\nggplot(diamonds, aes(carat, price)) + geom_smooth() +\n  facet_grid(~ cut)\n```\n\n\n\n\n\nFigure 2: A full width figure.\n\n\n\n\nOther chunk options related to figures can still be used, such as fig-width, fig-cap, and so on. For full width figures, usually fig-width is large and fig-height is small. In the above example, the plot size is \\(11 \\times 3\\)."
  },
  {
    "objectID": "Tufte_template_instructions.html#arbitrary-full-width-content",
    "href": "Tufte_template_instructions.html#arbitrary-full-width-content",
    "title": "Prediction of House Prices in Ames, Iowa",
    "section": "Arbitrary Full Width Content",
    "text": "Arbitrary Full Width Content\nAny content can span to the full width of the page, simply place the element in a div and add the class column-page-right. For example, the following code will display its contents as full width.\n::: {.fullwidth}\nAny _full width_ content here.\n:::\nBelow is an example:\n\nR is free software and comes with ABSOLUTELY NO WARRANTY. You are welcome to redistribute it under the terms of the GNU General Public License versions 2 or 3. For more information about these matters see https://www.gnu.org/licenses/."
  },
  {
    "objectID": "Tufte_template_instructions.html#main-column-figures",
    "href": "Tufte_template_instructions.html#main-column-figures",
    "title": "Prediction of House Prices in Ames, Iowa",
    "section": "Main Column Figures",
    "text": "Main Column Figures\nBesides margin and full width figures, you can of course also include figures constrained to the main column. This is the default type of figures in the LaTeX/HTML output.\n\n\nCode\n```{r}\n#| label: fig-main\n#| fig-cap: \"A figure in the main column.\"\nggplot(diamonds, aes(cut, price)) + geom_boxplot()\n```\n\n\n\n\n\nFigure 3: A figure in the main column."
  },
  {
    "objectID": "Tufte_template_instructions.html#margin-captions",
    "href": "Tufte_template_instructions.html#margin-captions",
    "title": "Prediction of House Prices in Ames, Iowa",
    "section": "Margin Captions",
    "text": "Margin Captions\nWhen you include a figure constrained to the main column, you can choose to place the figure’s caption in the margin by using the cap-location chunk option. For example:\n\n\nCode\n```{r}\n#| label: fig-main-margin-cap\n#| fig-cap: \"A figure with a longer caption. The figure appears in the main column, but the caption is placed in the margin. Captions can even contain elements like a citation such as @R-base.\"\n#| cap-location: margin\nggplot(diamonds, aes(cut, price)) + geom_boxplot()\n```\n\n\n\n\n\nFigure 4: A figure with a longer caption. The figure appears in the main column, but the caption is placed in the margin. Captions can even contain elements like a citation such as R Core Team (2023)."
  },
  {
    "objectID": "HousePrices.html#missing-values",
    "href": "HousePrices.html#missing-values",
    "title": "Prediction of House Prices in Ames",
    "section": "Missing Values",
    "text": "Missing Values\nFirst things first, read the full data description1. The manifest is available here. There you’ll find that for several columns missing values NA means actually “None”. The physical absence of a determined feature in a house is a category exposing the lack of such quality that can have a significant impact on the Sale Price (response).1 Tip: print a copy, make notes and study it. This is the first step to get into domain knowledge for Feature Engineering in the modelling phase.\nTherefore, I will fill the empty NA fields of the indicated columns of both datasets with the string “None”.\n\n\nCode\n```{r}\n#| label: easy replace_na\n\ncols_NA_to_none &lt;- list(\n  Alley = \"None\",\n  BsmtQual = \"None\", BsmtCond = \"None\", BsmtExposure = \"None\", BsmtFinType1 = \"None\", BsmtFinType2 = \"None\", \n  FireplaceQu = \"None\", \n  GarageType = \"None\", GarageFinish = \"None\", GarageQual = \"None\", GarageCond = \"None\", \n  PoolQC = \"None\",\n  Fence = \"None\", \n  MiscFeature = \"None\")\n\ndf_all &lt;- df_all |&gt;\n  replace_na(cols_NA_to_none) \n  \ndf_sub &lt;- df_sub |&gt;\n  replace_na(cols_NA_to_none)\n```\n\n\nOne of the early and recurrent steps of the EDA is to check the completeness of data. Let’s search for missing values, after filling indicated fields2. For this case I wrote the function count_na() that generates the tables displayed on the right margin.2 Tip: write a function to quantify missing values depending on the language and labelling system used.\n\n```{r}\n#| label: Counting NAs\n#| code-fold: false\n#| column: margin\n\ndf_all |&gt; \n  count_na() |&gt;  \n  knitr::kable(caption = 'Training dataset')\n\ndf_sub |&gt; \n  count_na() |&gt;  \n  knitr::kable(caption = 'Submission dataset')  \n```\n\n\n\nTraining dataset\n\n\nVariable\nNA_count\nPercent\n\n\n\n\nLotFrontage\n259\n17.74\n\n\nGarageYrBlt\n81\n5.55\n\n\nMasVnrType\n8\n0.55\n\n\nMasVnrArea\n8\n0.55\n\n\nElectrical\n1\n0.07\n\n\n\n\nSubmission dataset\n\n\nVariable\nNA_count\nPercent\n\n\n\n\nLotFrontage\n227\n15.56\n\n\nGarageYrBlt\n78\n5.35\n\n\nMasVnrType\n16\n1.10\n\n\nMasVnrArea\n15\n1.03\n\n\nMSZoning\n4\n0.27\n\n\nUtilities\n2\n0.14\n\n\nBsmtFullBath\n2\n0.14\n\n\nBsmtHalfBath\n2\n0.14\n\n\nFunctional\n2\n0.14\n\n\nExterior1st\n1\n0.07\n\n\nExterior2nd\n1\n0.07\n\n\nBsmtFinSF1\n1\n0.07\n\n\nBsmtFinSF2\n1\n0.07\n\n\nBsmtUnfSF\n1\n0.07\n\n\nTotalBsmtSF\n1\n0.07\n\n\nKitchenQual\n1\n0.07\n\n\nGarageCars\n1\n0.07\n\n\nGarageArea\n1\n0.07\n\n\nSaleType\n1\n0.07\n\n\n\n\nI will fill the remaining missing values as follow:\n\nThe LotFrontage column refers to the linear feet of street connected to the house. This feature is not well documented and the missing percentage related to other variables makes it unreliable, therefore, I will delete the feature.\nEverytime there is no garage, i.e., GarageType = \"None\", there is the corresponding missing value in Garage Year Built GarageYrBlt = NA. I will engineer a new feature called GarageNew with three ordinal categories: None, No, Yes. This based on the delta of YearBuilt - GarageYrBlt; I expect that given the house price, the algorithm will learn that “None” is worse than “No” and so on. Then I will remove the GarageYrBlt predictor.\nFor the rest of variables with a 1 % or less NA, I’ll calculate the median (if numerical) and the mode (if categorical) in order to fill them with it.\n\nHere’s my pipeline for both datasets:\n\n\nCode\n```{r}\n#| label: terminating NAs\n\n# \"replace_na_with_median\" is a custom function\n\ndf_all &lt;- df_all |&gt;\n  mutate(LotFrontage = NULL) |&gt;\n  mutate(GarageNew = if_else(YearBuilt - GarageYrBlt &gt; 0, \"Yes\", \"No\")) |&gt;\n  replace_na(list(GarageNew = \"None\")) |&gt;\n  mutate(GarageNew = factor(GarageNew, levels = c(\"None\", \"No\", \"Yes\"))) |&gt;\n  mutate(GarageYrBlt = NULL) |&gt;\n  mutate_if(is.numeric, replace_na_with_median)\n\ndf_sub &lt;- df_sub |&gt;\n  mutate(LotFrontage = NULL) |&gt;\n  mutate(GarageNew = if_else(YearBuilt - GarageYrBlt &gt; 0, \"Yes\", \"No\")) |&gt;\n  replace_na(list(GarageNew = \"None\")) |&gt;\n  mutate(GarageNew = factor(GarageNew, levels = c(\"None\", \"No\", \"Yes\"))) |&gt;\n  mutate(GarageYrBlt = NULL) |&gt;\n  mutate_if(is.numeric, replace_na_with_median)\n```\n\n\nLet’s get a list with the mode of each remaining columns containing missing values NA.\n\n\nCode\n```{r}\n#| label: Mode for NAs\n\n# Get the mode for reamaining columns with NAs:\n\n# Good and old-fashion code: apply(df_all, 2, find_mode)\n\nls_na_mode_all &lt;- df_all |&gt;\n  select(MasVnrType, MasVnrArea, Electrical) |&gt;\n  map(find_mode)\n\nls_na_mode_sub &lt;- df_sub |&gt; \n  select(MasVnrType, MasVnrArea, MSZoning, Utilities,   BsmtFullBath,   BsmtHalfBath,   Functional, Exterior1st,    Exterior2nd,    BsmtFinSF1, BsmtFinSF2, BsmtUnfSF,  TotalBsmtSF,    KitchenQual,    GarageCars, GarageArea, SaleType) |&gt;\n  map(find_mode)\n\n# Replace with the created named-lists\ndf_all &lt;- df_all |&gt;\n  replace_na(ls_na_mode_all) \n  \ndf_sub &lt;- df_sub |&gt;\n  replace_na(ls_na_mode_sub)\n\n# Check for last time for missing values:\nprint(\"Training dataset\")\ndf_all |&gt;\n  count_na()\n\nprint(\"Submission dataset\")\ndf_sub |&gt;\n  count_na()\n```\n\n\n[1] \"Training dataset\"\n[1] \"No missing values (NA) found.\"\n[1] \"Submission dataset\"\n[1] \"No missing values (NA) found.\"\n\n\n“The data is complete!” Let’s think about predictors."
  },
  {
    "objectID": "HousePrices.html#extract-data",
    "href": "HousePrices.html#extract-data",
    "title": "Prediction of House Prices in Ames",
    "section": "Extract Data",
    "text": "Extract Data\nI checked beforehands that there are no missing values, here NA, in the target variable SalePrice. Therefore, I will write a pipeline to read and concatenate both datasets (bind rows), adding and extra column dataset to label as “train” and “test” for further easy splitting1 (subset or filter).1 The whole Feature Transformation pipeline most be always the same for all predictors in both datasets.\n\n\nCode\n```{r}\n#| label: Load Data\n#| warning: false\n\names_train_raw &lt;- read_csv(\"./data/raw/train.csv\") # Train, validattion and test dataset\nprint(\"Dimensions of training dataset\")\ndim(ames_train_raw)\n\names_test_raw &lt;- read_csv(\"./data/raw/test.csv\")  # Features for submission dataset\nprint(\"Dimensions of test dataset containing only Feats.\")\ndim(ames_test_raw) \n\n# Add Target column with NA so both DFs can be concatenated:.id\names_test_raw &lt;- ames_test_raw |&gt; mutate(SalePrice = NA)\n\n# Binding and adding identifier column \"dataset\" \names_all &lt;- bind_rows(list(train = ames_train_raw, test = ames_test_raw), .id = \"dataset\")\n\nprint(\"Available variables:\")\nnames(ames_all)\n```\n\n\n[1] \"Dimensions of training dataset\"\n[1] 1460   81\n[1] \"Dimensions of test dataset containing only Feats.\"\n[1] 1459   80\n[1] \"Available variables:\"\n [1] \"dataset\"       \"Id\"            \"MSSubClass\"    \"MSZoning\"     \n [5] \"LotFrontage\"   \"LotArea\"       \"Street\"        \"Alley\"        \n [9] \"LotShape\"      \"LandContour\"   \"Utilities\"     \"LotConfig\"    \n[13] \"LandSlope\"     \"Neighborhood\"  \"Condition1\"    \"Condition2\"   \n[17] \"BldgType\"      \"HouseStyle\"    \"OverallQual\"   \"OverallCond\"  \n[21] \"YearBuilt\"     \"YearRemodAdd\"  \"RoofStyle\"     \"RoofMatl\"     \n[25] \"Exterior1st\"   \"Exterior2nd\"   \"MasVnrType\"    \"MasVnrArea\"   \n[29] \"ExterQual\"     \"ExterCond\"     \"Foundation\"    \"BsmtQual\"     \n[33] \"BsmtCond\"      \"BsmtExposure\"  \"BsmtFinType1\"  \"BsmtFinSF1\"   \n[37] \"BsmtFinType2\"  \"BsmtFinSF2\"    \"BsmtUnfSF\"     \"TotalBsmtSF\"  \n[41] \"Heating\"       \"HeatingQC\"     \"CentralAir\"    \"Electrical\"   \n[45] \"1stFlrSF\"      \"2ndFlrSF\"      \"LowQualFinSF\"  \"GrLivArea\"    \n[49] \"BsmtFullBath\"  \"BsmtHalfBath\"  \"FullBath\"      \"HalfBath\"     \n[53] \"BedroomAbvGr\"  \"KitchenAbvGr\"  \"KitchenQual\"   \"TotRmsAbvGrd\" \n[57] \"Functional\"    \"Fireplaces\"    \"FireplaceQu\"   \"GarageType\"   \n[61] \"GarageYrBlt\"   \"GarageFinish\"  \"GarageCars\"    \"GarageArea\"   \n[65] \"GarageQual\"    \"GarageCond\"    \"PavedDrive\"    \"WoodDeckSF\"   \n[69] \"OpenPorchSF\"   \"EnclosedPorch\" \"3SsnPorch\"     \"ScreenPorch\"  \n[73] \"PoolArea\"      \"PoolQC\"        \"Fence\"         \"MiscFeature\"  \n[77] \"MiscVal\"       \"MoSold\"        \"YrSold\"        \"SaleType\"     \n[81] \"SaleCondition\" \"SalePrice\"    \n\n\nIn order to organise my Data Budget I count on the train dataset with 1460 Observations of 79 predictors (one column is only an Id per house) and the Response, which is the SalePrice of the houses at the end of the list above.\nNote that Id and the just added dataset columns are not predictors. Hence, there are 79 features to play with. Also rememeber that the number of features for modelling will vary. Some will be discarded and some will be created along the analysis."
  },
  {
    "objectID": "HousePrices.html#feature-engineering",
    "href": "HousePrices.html#feature-engineering",
    "title": "Prediction of House Prices in Ames",
    "section": "Feature Engineering",
    "text": "Feature Engineering\nI have already started with the creation of a new predictor in the previous step, this to substitute the problematic variable GarageYrBlt that had a lot of missing values.\nFeature creation and transformations are not sequential, i.e., this is not the only step where Feature Engineering is applied. Think about the next modelling phase, where you want to reduce features, e.g., where new Principal Components are the new aggregators of original features.\nIn this part I will establish which variables are categorical and numerical; this is not always as obvious as it seems4.4 Integer variables like calendar Years can be treated as categories for the analysis.\nThe first easy thing that comes to mind is to add the total area of the property as a new column named TotAreaSF; SF means Squared Feet.\nAfter that, I check the data documentation to see which variables can be thought as categoricals (factors); this can be tedeous if Real Estate is not your domain of expertise.\nAfter 1.5 hours of reading, googling, understanding other notebooks and deliberating (yes, it was tedeous), I can summarise four types of ways to engineer new features depending on the nature of the variables:\n\nAggregation to a total of continous-numerical surface area (Square Feet), e.g. new TotInteriorArea Feat. summing basement and floors, etc. Same for a new TotExteriorArea. Then deleting the addends variables.\nAggregation to a total of numerical counts of an available installation of a determined type, e.g. new TotBaths. Then deleting the addends.\nCategorisation with ascending quality levels of the originally numerical variables OverallQual and OverallCond.\nCreation of new binary features that state if a determined installation exists or doesn’t.\n\nHere’s the code that complies with the four previous steps:\n\n\nCode\n```{r}\n#| label: Feature Engineering\n\n# --- Total Aggregations ----\names_all &lt;- ames_all |&gt;\n\n  # Continuous numerical ----\n  # NEW TotalInteriorArea\n  mutate(TotInteriorArea = BsmtFinSF1 + BsmtFinSF2 + `1stFlrSF` + `2ndFlrSF`) |&gt;\n  select(-c(BsmtFinSF1, BsmtFinSF2, `1stFlrSF`))|&gt; # Bye bye...\n\n  # NEW TotalExteriorArea\n  mutate(TotExteriorArea = WoodDeckSF + OpenPorchSF + EnclosedPorch + `3SsnPorch` + ScreenPorch) |&gt;\n  select(-c(WoodDeckSF, OpenPorchSF, EnclosedPorch, `3SsnPorch`, ScreenPorch)) |&gt;# Bye bye...\n\n  # Counting numerical ----\n  # NEW TotalBaths\n  mutate(TotBaths = BsmtFullBath + 0.5 * BsmtHalfBath + FullBath + 0.5 * HalfBath) |&gt; \n  select(-c(BsmtFullBath, BsmtHalfBath, FullBath, HalfBath)) # Bye bye...\n\n\n# ---- Ordered Categorical Features ----\names_all &lt;- ames_all |&gt;\n  mutate(OverallQual = factor(OverallQual)) |&gt;\n  mutate(OverallCond = factor(OverallCond))  # Check level orders 1, ..., 10 (BEST)\n\n\n# ---- Binary Features ----\n# Does the installation exist? \n\names_all &lt;- ames_all |&gt;\n  # CentralAir\n  mutate(CentralAir = if_else(CentralAir == \"N\", \"No\", \"Yes\")) |&gt;\n  mutate(CentralAir = fct_relevel(CentralAir, \"No\", \"Yes\"))|&gt;\n\n  # NEW IsRemodelled (it will replace YearRemodAdd)\n  mutate(IsRemodelled = if_else(YearRemodAdd - YearBuilt &gt; 0, \"Yes\", \"No\")) |&gt;\n  mutate(IsRemodelled = factor(IsRemodelled, levels = c(\"No\", \"Yes\"))) |&gt;\n  select(-YearRemodAdd) |&gt; # Bye YearRemodAdd\n\n  # NEW ExistPool\n  mutate(ExistPool = if_else(PoolArea == 0, \"No\", \"Yes\")) |&gt;\n  mutate(ExistPool = fct_relevel(ExistPool, \"No\", \"Yes\"))|&gt;\n\n  # NEW ExistGarage\n  mutate(ExistGarage = if_else(GarageArea == 0, \"No\", \"Yes\")) |&gt;\n  mutate(ExistGarage = fct_relevel(ExistGarage, \"No\", \"Yes\"))|&gt;\n\n  # NEW ExistBsmt\n  mutate(ExistBsmt = if_else(TotalBsmtSF == 0, \"No\", \"Yes\")) |&gt;\n  mutate(ExistBsmt = fct_relevel(ExistBsmt, \"No\", \"Yes\"))|&gt;\n\n  # NEW Exist2ndFloor\n  mutate(Exist2ndFloor = if_else(`2ndFlrSF` == 0, \"No\", \"Yes\")) |&gt;\n  select(-`2ndFlrSF`) |&gt; # Bye, bye... \n  mutate(Exist2ndFloor = fct_relevel(Exist2ndFloor, \"No\", \"Yes\")) |&gt;\n\n  # NEW ExistFireplace\n  mutate(ExistFireplace = if_else(Fireplaces == 0, \"No\", \"Yes\")) |&gt;\n  mutate(ExistFireplace = fct_relevel(ExistFireplace, \"No\", \"Yes\"))\n\n\n# ---- The rest are factors ----\n# I'm going to assume that the rest are Categorical variables \n\names_all &lt;- ames_all |&gt;\n  mutate(across(where(is.character), factor))\n\n# ---- Numerical Features ----\n\n# BedroomabvGr (count) left numerical \n# Kitchens (count) left numerical \n# TotRmsAbvGrd (count) left numerical\n# Fireplaces (count) left numerical\n# GarageCars (count) left numerical\n# GarageArea (continous) left numerical \n# MiscVal left numerical \n# MasVnrArea (continous) left numeric\n\n\n# ---- Remove 'LowQualFinSF' ----\n\n# Low quality finished square feet (all floors)\n# Most of the values are 0 -&gt; almost 0 variance. \names_all$LowQualFinSF &lt;- NULL\n```\n\n\nNote that I replaced YearRemodAdd to a simpler binary IsRemodelled variable, similar to what I did with the new GarageNew column.\nOK! Let’s move on.\n\nSearching for simple correlations\nAlthough nothing is linear, is good to have an idea of simple correlations between all variables; it gives me an idea of what kind of plots to make. After going through the previous steps, it’s obvious that there are correlations. Think about the number of cars that fit in a garage GarageCars and the area of the garage GarageArea.\n\n\nCode\n```{r}\n#| label: fig-num-corr\n#| fig-width: 8\n#| fig-height: 8\n#| fig-cap: Pearson's correlation of numeric features and response. High multicollinearity.\n#| warning: false\n#| message: false\n\nlibrary(corrplot)\n\names_all |&gt;\n  filter(dataset == \"train\") |&gt;\n  select(-c(dataset, Id)) |&gt;\n  select(where(is.numeric)) |&gt;  \n  cor(method = \"pearson\") |&gt;\n  corrplot(type = \"lower\", method = \"circle\", insig = 'blank', order = \"hclust\", diag = TRUE,\n  tl.col=\"black\", tl.cex = 0.8, addCoef.col = 'black', number.cex = 0.6)\n```\n\n\n\n\n\nFigure 2: Pearson’s correlation of numeric features and response. High multicollinearity.\n\n\n\n\nAccording to the matrix above, GrLivArea has the strongest linear relationship with the target SalePrice, followed by TotInteriorArea, this given the collinearity with GrLivArea, and then GarageArea or GarageCars, both heavily correlated too, like commented before.\nI’m leaving blank, i.e., without a circle, the insignificant correlations for better visualisation and focus. Now I’m checking the categorical variables and the response.\n\n\nCode\n```{r}\n#| label: fig-cat-corr\n#| fig-width: 10\n#| fig-height: 10\n#| fig-cap: Pearson's correlation of categorical features and response.\n#| warning: false\n#| message: false\n\names_all |&gt;\n  filter(dataset == \"train\") |&gt;\n  select(-dataset) |&gt;\n  select(where(is.factor) | contains(\"Price\")) |&gt;  \n  mutate_if(is.factor, as.integer) |&gt; \n  cor(method = \"pearson\") |&gt;\n  corrplot(type = \"lower\", order=\"hclust\", diag = TRUE, insig = 'blank',\n  tl.col=\"black\", tl.cex = 0.8, number.cex = 0.6)\n```\n\n\n\n\n\nFigure 3: Pearson’s correlation of categorical features and response.\n\n\n\n\nThe best linear association with SalePrice is given by OverallQual factor, followed by everything else that has to do with quality ratings.\nHere, the highest collinearity is showed between PoolQC and the new ExistPool variables. This is because they share a majority ammount of “None” and “No” values respectivelly in the exact same positions, therefore making the information redundant. In case of one-hot enconding there would be two repeated colums.\nOverall, one can see clearly the multicollinearity clusters, which suggest the use of advance Feature Selection techniques.\n\n\nVisual Exploration\nNow with the previous information in hand, I’m going to visualise separatelly the two most important quasi-linear relationsships: GrLivArea and OverallQual vs. SalePrice.\n\n\nCode\n```{r}\n#| label: fig-cont_linear\n#| message: false\n#| warning: false\n#| column: body\n#| fig-width: 6\n#| fig-height: 6\n#| fig-cap: 'GrvLivArea Vs. SalePrice - The most \"linear\" realationship between continuous variables. One can clearly notice the increase of variance as both, Living Area and Price increase, i.e., heteroskedasticity.'\n#| cap-location: margin\n#| fig-subcap:\n#|   - \"Scatter Plot\"\n#|   - \"Hexbin Plot\"\n#| layout-ncol: 2\n\names_all |&gt;\n  filter(dataset == \"train\") |&gt;\n  ggplot(aes(x = GrLivArea, y = SalePrice/1000)) +  \n  scale_y_continuous(breaks = seq(0, 800, 50), labels = scales::comma) +  \n  labs(x = expression(\"Ground Living Area [\"~ft^2~\"]\"), \n       y = \"Sale\\nPrice\\n['000 $]\") +  \n  geom_point(aes(color = OverallQual), alpha = 0.5) + theme(axis.text.y = element_blank()) +\n  geom_smooth(method = \"lm\", formula =  y ~ splines::bs(x, 3), color = \"black\", size = 1.5, alpha = 0.5) +\n  theme(legend.position = \"bottom\")\n\n# install.packages(\"hexbin\")\names_all |&gt;\n  filter(dataset == \"train\") |&gt;\n  ggplot(aes(x = GrLivArea, y = SalePrice/1000)) +  \n  scale_y_continuous(breaks = seq(0, 800, 50), labels = scales::comma) +    \n  geom_hex(bins = 35, colour = \"seagreen\") + \n  labs(x = expression(\"Ground Living Area [\"~ft^2~\"]\")) +    \n  theme(axis.title.y = element_blank(), legend.position = \"bottom\")\n```\n\n\n\n\n\n\n\n\n(a) Scatter Plot\n\n\n\n\n\n\n\n(b) Hexbin Plot\n\n\n\n\nFigure 4: GrvLivArea Vs. SalePrice - The most “linear” realationship between continuous variables. One can clearly notice the increase of variance as both, Living Area and Price increase, i.e., heteroskedasticity.\n\n\n\nThe hexbin plot reveals three cells of price and size where houses are more common in the training dataset. There are more than 50 houses for each bin in the range of 130K, 140K and 180K USD aproximately.\nOn the other hand, note how problematic are the outliers with the spline fit! This visual allows me to remove outliers, i.e., the biggest and cheap houses (right data points).\n\n\nCode\n```{r}\n#| label: fig-RemoveOutliers\n#| fig-cap: Removing three outliers the spline fit is dramatically improved!\n#| column: margin\n\names_all |&gt;\n  select(c(SalePrice, GrLivArea, OverallQual, YrSold)) |&gt;\n  filter(GrLivArea &gt; 4500) |&gt;\n  glimpse()\n\names_all &lt;- ames_all |&gt; filter(GrLivArea &lt; 4500)\n\names_all |&gt;\n  filter(dataset == \"train\") |&gt;\n  ggplot(aes(x = GrLivArea, y = SalePrice/1000)) +  \n  scale_y_continuous(breaks = seq(0, 800, 50), labels = scales::comma) +  \n  labs(x = expression(\"Ground Living Area [\"~ft^2~\"]\"), \n       y = \"Sale Price ['000 $]\") +  \n  geom_point(aes(color = OverallQual), alpha = 0.5) + theme(axis.text.y = element_blank()) +\n  geom_smooth(method = \"lm\", \n              formula =  y ~ splines::bs(x, 3), \n              color = \"black\", \n              size = 1.5, \n              alpha = 0.5) +\n  theme(legend.position = \"none\", axis.title.y = element_text(angle = 90))\n```\n\n\nRows: 3\nColumns: 4\n$ SalePrice   &lt;dbl&gt; 184750, 160000, 163000\n$ GrLivArea   &lt;dbl&gt; 4676, 5642, 5095\n$ OverallQual &lt;fct&gt; 10, 10, 10\n$ YrSold      &lt;dbl&gt; 2007, 2008, 2007\n\n\n\n\n\n\nFigure 5: Removing three outliers the spline fit is dramatically improved!\n\n\n\nThe three big houses above were like super offers! Or did the housing bubble exploded?\nIn the same fashion, I want to see the effect of the factor OverallQual.\n\n\nCode\n```{r}\n#| label: fig-cat_linear\n#| message: false\n#| warning: false\n#| fig-width: 7\n#| fig-height: 8\n#| fig-cap: 'OverallQual Vs. SalePrice - The most \"linear\" realationship with a categorical predictor. The raincloud plot shows how variances of factors are very different.'\n\n# install.packages(\"ggrain\")\nlibrary(ggrain)\n\names_all |&gt;\n  filter(dataset == \"train\") |&gt;\n  ggplot(aes(x = OverallQual, y = SalePrice/1000, colour = OverallQual, fill = OverallQual)) +     \n  geom_rain(alpha = 0.3) +  \n  scale_y_continuous(breaks = seq(0, 800, 100)) +  \n  labs(x = \"Overall\\nQuality\", y = \"Sale Price ['000 $]\") +\n  coord_flip() + \n  theme(legend.position = \"none\")\n```\n\n\n\n\n\nFigure 6: OverallQual Vs. SalePrice - The most “linear” realationship with a categorical predictor. The raincloud plot shows how variances of factors are very different.\n\n\n\n\n\nI’m wondering in which price range is the most popular quality?\n\n```{r}\n#| label: fig-count_overallQual\n#| cap-location: margin\n#| fig-cap: 'Houses with mid-quality levels are most frequent in the train dataset. I will reduce the categories to nine (9), grouping or lumping 1 and 2 as \"Other\".'\n#| column: margin\n#| code-fold: false\n\names_all |&gt;\n  filter(dataset == \"train\") |&gt;\n  count(OverallQual, name = \"count\") |&gt;\n  ggplot(aes(y = fct_reorder(OverallQual, count), x = count)) + \n  geom_col(aes(fill = OverallQual)) +\n  geom_text(aes(label = count)) +\n  labs(y = \"Overall Quality\") + \n  theme(legend.position = \"none\", axis.title.y = element_text(angle = 90))\n```\n\n\n\n\n\nFigure 7: Houses with mid-quality levels are most frequent in the train dataset. I will reduce the categories to nine (9), grouping or lumping 1 and 2 as “Other”.\n\n\n\nIt seems that most popular houses, with an overall qualilty of 5 (mid-quality level), are the ones between 120K and 145K USD. Of course, this was back in the years of 2006 - 2010.\nNow I’ll group or lump into one category OverallQual = 1 and OverallQual = 2.\n\n\nCode\n```{r}\n#| label: lumping\n\names_all &lt;- \n  ames_all |&gt;\n  mutate(OverallQual = fct_lump(OverallQual, n = 8)) |&gt;\n  mutate(OverallQual = fct_relevel(OverallQual, \"Other\")) \n```\n\n\n\n\nHow the sale price varies depending on the living area by house styles?\n\n\nCode\n```{r}\n#| label: fig-houseStyles\n#| fig-column: page-right\n#| fig-width: 8\n#| fig-height: 8\n#| fig-cap: \"One and two story houses are the most common within the train dataset.\"\n\names_all |&gt;\n  filter(dataset == \"train\") |&gt;\n  ggplot(aes(x = GrLivArea, y = SalePrice/1000)) +  \n  scale_y_continuous(breaks = seq(0, 800, 50), labels = scales::comma) +  \n  labs(x = expression(\"Ground Living Area [\"~ft^2~\"]\"), \n       y = \"Sale\\nPrice\\n['000 $]\") +  \n  geom_point(aes(color = OverallQual), alpha = 0.3) +\n  geom_smooth(method = \"lm\", \n              formula =  y ~ splines::bs(x, 3), \n              color = \"black\",\n              se = FALSE,\n              size = 0.7, \n              alpha = 0.5) +\n  facet_wrap( ~HouseStyle, nrow = 2) +\n  theme(legend.position = \"bottom\")\n```\n\n\n\n\n\nFigure 8: One and two story houses are the most common within the train dataset.\n\n\n\n\n\n\n\nAnalysis of response SalePrice\nHow well-behaved is the target?\n\n\nCode\n```{r}\n#| label: fig-Y\n#| message: false\n#| warning: false\n#| column: body\n#| fig-width: 6\n#| fig-height: 6\n#| fig-cap: \"Analysis of the target variable. All the assumptions of OLS and linear regression are broken, as usual.\"\n#| fig-subcap:\n#|   - \"Histogram\"\n#|   - \"Q-Q Plot\"\n#| layout-ncol: 2\n\names_all |&gt;\n  filter(dataset == \"train\") |&gt;\n  ggplot(aes(x = SalePrice/1000)) +  \n  geom_histogram(bins = 50, color = \"seagreen\", fill = \"seagreen\", alpha = 0.5) +\n  scale_x_continuous(breaks = seq(0, 800, 50), labels = scales::comma) +  \n  labs(x = \"Sale Price ['000 $]\")\n\names_all |&gt;\n  filter(dataset == \"train\") |&gt; \n  ggplot(aes(sample = SalePrice/1000)) + \n  stat_qq(color = \"seagreen\", alpha = 0.5) + \n  stat_qq_line(color = \"seagreen\") +  \n  scale_y_continuous(breaks = seq(0, 800, 50), labels = scales::comma) +\n  labs(y = \"Sale\\nPrice\\n['000 $]\",\n       x = \"Theoretical Quantiles (Norm. Dist.)\")\n```\n\n\n\n\n\n\n\n\n(a) Histogram\n\n\n\n\n\n\n\n(b) Q-Q Plot\n\n\n\n\nFigure 9: Analysis of the target variable. All the assumptions of OLS and linear regression are broken, as usual.\n\n\n\nClearly, the target variable (Y) is not well-bahaved. It shows a log-normal distribution heavily skewed, to right of course. In order to achieve better predictions, a transformation might be needed.\n\nTransformation of the response\nFor what I’ve seen, processes that have to do with money, e.g., sale prices, costs of products, salaries, they are most of the time Log-normal. Rarely there is something free, so you don’t have zeros or with negativ value; think about the top 1% of reach people, or anything that becomes premium the higher the price. These are long and sparsed right tails.\nThe logarithmic transformation works when there are few large values, like in this case, there are only a few expensive hauses. The logarithm scale will shrink that right tail5, making the distribution more normal-like.5 Think of a Logarithmic transformation like pressing an accordeon only from your right arm.\nNevertheless, the moment the first data transformation is performed, we start to loose interpretability very quickly. Nowadays, the most accurate predictions need more than one transformation in order to work best6.6 Forget about linearity and interpretability if you want the most accurate results.\nBecause we have powerful computers and libraries with written functions to perform variable transformations, I will use the Box-Cox transformation, which is a family of functions that includes the logarithmic one depending on the value of a parameter lambda. This parameter is automatically assessed.\n\n\nBox-Cox transformations:\n\n\\(y(\\lambda) = \\begin{cases} \\frac{y^{-1}-1}{\\lambda}, & \\text{if } \\lambda \\neq 0 \\\\ \\log y, & \\text{if } \\lambda = 0 \\end{cases}\\)\n\n```{r}\n#| label: fig-boxcox\n#| fig-cap: \"Best parameter lambda = -0.05050505. It is almost a pure logarithmic transformation.\"\n#| column: margin\n#| code-fold: false\n#| warning: false\n#| message: false\n\nboxcox_trans &lt;- MASS::boxcox(lm(SalePrice ~ 1, \n                                data = subset(ames_all, dataset == \"train\")), \n                             lambda = seq(-1, 1), \n                             plotit = TRUE)\n\nlambda &lt;- as.numeric(boxcox_trans$x[which.max(boxcox_trans$y)])\n\n# New transformed response variable\names_all &lt;- ames_all |&gt;\n  mutate(SalePrice_bc = (SalePrice^lambda - 1) / lambda)\n```\n\n\n\n\n\nFigure 10: Best parameter lambda = -0.05050505. It is almost a pure logarithmic transformation.\n\n\n\nThe new column SalePrice_bc should be better behaved…\n\n\nCode\n```{r}\n#| label: fig-Y-trans\n#| message: false\n#| warning: false\n#| column: body\n#| fig-width: 6\n#| fig-height: 6\n#| fig-cap: \"The transformed response shows a more bell-like shape.\"\n#| fig-subcap:\n#|   - \"Histogram\"\n#|   - \"Q-Q Plot\"\n#| layout-ncol: 2\n\names_all |&gt;\n  filter(dataset == \"train\") |&gt;\n  ggplot(aes(x = SalePrice_bc)) +  \n  geom_histogram(bins = 50, color = \"seagreen\", fill = \"seagreen\", alpha = 0.5) +  \n  labs(x = \"Sale Price [Box-Cox]\")\n\names_all |&gt;\n  filter(dataset == \"train\") |&gt; \n  ggplot(aes(sample = SalePrice_bc)) + \n  stat_qq(color = \"seagreen\", alpha = 0.5) + \n  stat_qq_line(color = \"seagreen\") +   \n  labs(y = \"Sale\\nPrice\\n[Box-Cox]\", x = \"Theoretical Quantiles (Norm. Dist.)\")\n```\n\n\n\n\n\n\n\n\n(a) Histogram\n\n\n\n\n\n\n\n(b) Q-Q Plot\n\n\n\n\nFigure 11: The transformed response shows a more bell-like shape.\n\n\n\n… and it is, indeed. Well, except for the tails, now the transformed values are more normal-like at the core.\nI will include the transformation of the response as a step within a recipe in the modelling phase."
  },
  {
    "objectID": "HousePrices.html#footnotes",
    "href": "HousePrices.html#footnotes",
    "title": "Prediction of House Prices in Ames",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTip: print a copy, make notes and study it. This is the first step to get into domain knowledge for Feature Engineering in the modelling phase.↩︎\nTip: write a function to quantify missing values depending on the language and labelling system used.↩︎\nTip: integer variables like calendar Years can be treated as categories for the analysis.↩︎\nTip: visualise a Logarithmic transformation like pressing an accordeon only from your right side.↩︎\nTip: visualise a Logarithmic transformation like pressing an accordeon only from your right side.↩︎"
  },
  {
    "objectID": "HousePrices.html#impute-missing-values",
    "href": "HousePrices.html#impute-missing-values",
    "title": "Prediction of House Prices in Ames",
    "section": "Impute Missing Values",
    "text": "Impute Missing Values\nFirst things first, read the full data description2. There you’ll find that for several columns, missing values NA means actually “None”. The physical absence of a determined feature in a house is a category exposing the lack of such quality that can have a significant impact on the response SalePrice. Later it is most probably that binary features indicating the existance of some installations should be created.2 Print a copy, make notes and study it. This is the first step to get into domain knowledge, in this case Real Estate, for later Feature Engineering.\nTherefore, I will fill the empty NA fields of the indicated columns of both datasets with the string “None”.\n\n\nCode\n```{r}\n#| label: easy replace_na\n\ncols_NA_to_none &lt;- list(\n  Alley = \"None\",\n  BsmtQual = \"None\", BsmtCond = \"None\", BsmtExposure = \"None\", BsmtFinType1 = \"None\", BsmtFinType2 = \"None\", \n  FireplaceQu = \"None\", \n  GarageType = \"None\", GarageFinish = \"None\", GarageQual = \"None\", GarageCond = \"None\", \n  PoolQC = \"None\",\n  Fence = \"None\", \n  MiscFeature = \"None\")\n\names_all &lt;- ames_all |&gt;\n  replace_na(cols_NA_to_none)   \n```\n\n\nOne of the early and recurrent steps of the EDA is to check the completeness of data. Let’s search for missing values, after filling indicated fields3. For this case I wrote the function count_na() that generates the table displayed on the right margin.3 Write a function to quantify missing values depending on the language and labelling system used.\n\n```{r}\n#| label: Counting NAs\n#| code-fold: false\n#| column: margin\n\n# Remaining NA count leaving out target SalePrice\names_all |&gt; \n  select(-SalePrice) |&gt;\n  count_na() |&gt;  \n  knitr::kable(caption = 'Ames dataset')\n```\n\n\n\nAmes dataset\n\n\nVariable\nNA_count\nPercent\n\n\n\n\nLotFrontage\n486\n16.65\n\n\nGarageYrBlt\n159\n5.45\n\n\nMasVnrType\n24\n0.82\n\n\nMasVnrArea\n23\n0.79\n\n\nMSZoning\n4\n0.14\n\n\nUtilities\n2\n0.07\n\n\nBsmtFullBath\n2\n0.07\n\n\nBsmtHalfBath\n2\n0.07\n\n\nFunctional\n2\n0.07\n\n\nExterior1st\n1\n0.03\n\n\nExterior2nd\n1\n0.03\n\n\nBsmtFinSF1\n1\n0.03\n\n\nBsmtFinSF2\n1\n0.03\n\n\nBsmtUnfSF\n1\n0.03\n\n\nTotalBsmtSF\n1\n0.03\n\n\nElectrical\n1\n0.03\n\n\nKitchenQual\n1\n0.03\n\n\nGarageCars\n1\n0.03\n\n\nGarageArea\n1\n0.03\n\n\nSaleType\n1\n0.03\n\n\n\n\nI’ll fill the remaining missing values as follow:\n\nThe LotFrontage column refers to the linear feet of street connected to the house. This feature is not well documented and the missing percentage related to other variables makes it not only unreliable, but very low in variance. Therefore, I will delete the feature.\nEverytime a Garage doesn’t exist, i.e., GarageType = \"None\", there is the corresponding missing value in Garage Year Built GarageYrBlt = NA. I will engineer a new feature called GarageNew with three ordinal categories: None, No, Yes. This based on the delta of YearBuilt - GarageYrBlt; I expect that given the house price, the algorithm will learn that “None” is worse than “No” and so on. Then I will remove the GarageYrBlt predictor.\nFor the rest of variables with a 1 % or less missing values NA, I’ll calculate the median (if numerical) and the mode (if string) in order to fill them with it.\n\nHere’s my pipeline for the whole dataset:\n\n\nCode\n```{r}\n#| label: terminating NAs\n\n# \"replace_na_with_median\" is a custom function\n\names_all &lt;- ames_all |&gt;\n  mutate(LotFrontage = NULL) |&gt; # Removing LotFrontage\n  mutate(GarageNew = if_else(YearBuilt - GarageYrBlt &gt; 0, \"Yes\", \"No\")) |&gt; # New Feat.\n  replace_na(list(GarageNew = \"None\")) |&gt;\n  mutate(GarageNew = factor(GarageNew, levels = c(\"None\", \"No\", \"Yes\"))) |&gt; # 3 levels\n  mutate(GarageYrBlt = NULL) |&gt; # Removing old Feat.\n  mutate_if(is.numeric, replace_na_with_median)\n```\n\n\nLet’s get a list with the mode of each remaining columns containing missing values NA.\n\n\nCode\n```{r}\n#| label: Mode for NAs\n\n# Get the mode for reamaining columns with NAs:\n# \"find_mode()\" is a custom function.\n\n# Good, old-fashioned code: apply(ames_all, 2, find_mode)\n\nlist_na_mode &lt;- ames_all |&gt; \n  select(MasVnrType, MasVnrArea, MSZoning, Electrical, Utilities,   BsmtFullBath,   BsmtHalfBath,   Functional, Exterior1st,    Exterior2nd,    BsmtFinSF1, BsmtFinSF2, BsmtUnfSF,  TotalBsmtSF,    KitchenQual,GarageCars, GarageArea, SaleType) |&gt;\n  map(find_mode)\n\n# map returns a list \n\n# Replace with the created named-lists\names_all &lt;- ames_all |&gt;\n  replace_na(list_na_mode) \n\n# Sanity check of missing values:\nprint(\"Full Ames dataset (train and test)\")\names_all |&gt;\n  select(-SalePrice) |&gt;\n  count_na()\n```\n\n\n[1] \"Full Ames dataset (train and test)\"\n[1] \"No missing values (NA) found.\"\n\n\n“The data is complete!” Let’s think about predictors."
  },
  {
    "objectID": "HousePrices.html#simple-model-as-reference",
    "href": "HousePrices.html#simple-model-as-reference",
    "title": "Prediction of House Prices in Ames",
    "section": "Simple Model as Reference",
    "text": "Simple Model as Reference"
  },
  {
    "objectID": "HousePrices.html#model-selection",
    "href": "HousePrices.html#model-selection",
    "title": "Prediction of House Prices in Ames",
    "section": "Model Selection",
    "text": "Model Selection"
  },
  {
    "objectID": "HousePrices.html#reference-model",
    "href": "HousePrices.html#reference-model",
    "title": "Prediction of House Prices in Ames",
    "section": "Reference Model",
    "text": "Reference Model\n\n\nCode\n```{r}\n#| label: ReferenceModel\n\n# Model 1 Setup\nmodel_lm &lt;-  linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  set_mode(\"regression\")\n\n# Workflow\n\names_wf &lt;- workflow() |&gt;\n  add_model(model_lm) |&gt;\n  add_formula(SalePrice ~ GrLivArea)\n\n\n# Fit models to validation folds\n\ntrained_models &lt;- fit_resamples(object = ames_wf, resamples = ames_boots)\n\n# See estimated performance\ntrained_models |&gt; \n  collect_metrics(summarize = TRUE) # TRUE gets Avg. performance \n\n\n\n# Modern DS is a mixed territory. That's what make it so effective and with rapid advances\n# Every knowledge domain claiming the right terminology\n# Goodness of prediction (test )\n# Goodness of fit - seen data (train )  not realistic metric here \n```\n\n\n# A tibble: 2 × 6\n  .metric .estimator      mean     n   std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   54038.     1000 71.5      Preprocessor1_Model1\n2 rsq     standard       0.539  1000  0.000984 Preprocessor1_Model1"
  },
  {
    "objectID": "HousePrices.html#choosing-resampling-technique",
    "href": "HousePrices.html#choosing-resampling-technique",
    "title": "Prediction of House Prices in Ames",
    "section": "Choosing Resampling Technique",
    "text": "Choosing Resampling Technique\nDepending on the chosen resample technique to estimate the Goodness-of-Fit (test error) Take a look at the pristine explanation by (Zablotski 2022).\n\nSimple validation? 1 train fold and 1 test fold: NO, it’s old and innacurate.\nv-folds Cross-Validation? Analysis (training folds), Assessment (validation folds) and test: it’s small data, I can choose something even more powerful.\nBootstrap Sampling? YES.\n\nBy today’s standards this dataset is small, therefore I will choose Bootstraping to keep the chosen samples the same size as the training set. The probability of an observation of being sample at least once is 0.63, therefore the complementary training set (around 37%) will become the assessment set. Although performance metrics will be slightly conservative or pesimistic, I prefer it.\nI will generate 1000 bootstrapped samples.\n\nExpending Data Budget\nNormally with v-fold CV I expend my data budget, but here doing resampling with replacement is kind of printing money…\nHere’s the code to generate the bootstraps and therefore split the data budget:\n\n\nCode\n```{r}\n#| label: DataBudget\n#| warning: false\n#| fold: false\n\n# install.packages(\"tidymodels\")\nlibrary(tidymodels)\ntidymodels_prefer()\n# conflicted::conflicts_prefer(scales::discard)\n\n# Select the pre-processed training dataset\names_train &lt;- \n  ames_all |&gt; \n  filter(dataset == \"train\") |&gt;\n  select(-Id)\n\n# v-folds CV repeated 10 times (v x 10 models)\n# ames_folds &lt;- vfold_cv(ames_train, v = 8, repeats = 10, strata = SalePrice) # v = 10 folds are default\n\n# Generate 1000 bootstrapped samples\nset.seed(1982)\names_boots &lt;- bootstraps(ames_train, times = 1000)\names_boots  \n```\n\n\n# A tibble: 1,000 × 2\n   splits             id           \n   &lt;list&gt;             &lt;chr&gt;        \n 1 &lt;split [1458/547]&gt; Bootstrap0001\n 2 &lt;split [1458/532]&gt; Bootstrap0002\n 3 &lt;split [1458/552]&gt; Bootstrap0003\n 4 &lt;split [1458/511]&gt; Bootstrap0004\n 5 &lt;split [1458/506]&gt; Bootstrap0005\n 6 &lt;split [1458/548]&gt; Bootstrap0006\n 7 &lt;split [1458/537]&gt; Bootstrap0007\n 8 &lt;split [1458/532]&gt; Bootstrap0008\n 9 &lt;split [1458/527]&gt; Bootstrap0009\n10 &lt;split [1458/539]&gt; Bootstrap0010\n# ℹ 990 more rows"
  },
  {
    "objectID": "HousePrices.html#expending-the-data-budget",
    "href": "HousePrices.html#expending-the-data-budget",
    "title": "Prediction of House Prices in Ames",
    "section": "Expending the Data Budget",
    "text": "Expending the Data Budget"
  },
  {
    "objectID": "HousePrices.html#expending-data-budget",
    "href": "HousePrices.html#expending-data-budget",
    "title": "Prediction of House Prices in Ames",
    "section": "Expending Data Budget",
    "text": "Expending Data Budget\n\n\nCode\n```{r}\n#| label: Data Budget\n#| warning: false\n\n# install.packages(\"tidymodels\")\nlibrary(tidymodels)\ntidymodels_prefer()\n# conflicted::conflicts_prefer(scales::discard)\n\n# Select the pre-processed training dataset\names_train &lt;- ames_all |&gt; filter(dataset == \"train\")\n\n# v-folds CV repeated 10 times (v x 10 models)\n# ames_folds &lt;- vfold_cv(ames_train, v = 8, repeats = 10, strata = SalePrice) # 10 folds are default\n\n# Generate 1000 bootstrapped samples\nset.seed(1982)\names_boots &lt;- bootstraps(ames_train, times = 1000)\names_boots\n```\n\n\n# A tibble: 1,000 × 2\n   splits             id           \n   &lt;list&gt;             &lt;chr&gt;        \n 1 &lt;split [1458/547]&gt; Bootstrap0001\n 2 &lt;split [1458/532]&gt; Bootstrap0002\n 3 &lt;split [1458/552]&gt; Bootstrap0003\n 4 &lt;split [1458/511]&gt; Bootstrap0004\n 5 &lt;split [1458/506]&gt; Bootstrap0005\n 6 &lt;split [1458/548]&gt; Bootstrap0006\n 7 &lt;split [1458/537]&gt; Bootstrap0007\n 8 &lt;split [1458/532]&gt; Bootstrap0008\n 9 &lt;split [1458/527]&gt; Bootstrap0009\n10 &lt;split [1458/539]&gt; Bootstrap0010\n# ℹ 990 more rows"
  },
  {
    "objectID": "HousePrices.html#reference-models",
    "href": "HousePrices.html#reference-models",
    "title": "Prediction of House Prices in Ames",
    "section": "Reference Models",
    "text": "Reference Models\nMy final objective is to stack (combine or ensemble) several models of different nature at the end.\nHowever, for a first model I’d like to keep interpretability and to involve all predictors in order to apply some regularisation given the problem of multicollinearity. Hence, I’ll go with a regularised (shrinkage) General Linear Model, GLM. In this manner I can have a first look at feature importance.\nThe model will be the best of Lasso (L1) and Ridge (L2), i.e., Elastic-Net\nThe following code shows preprocessing steps enclosed in a pipeline or recipe:\n\n\nCode\n```{r}\n#| label: Preprocessing\n\n# ---- Base recipe ----\nbase_recipe &lt;-\n  recipe(SalePrice ~ GrLivArea + OverallQual, data = ames_train)\n\n# Recipe for trees  \ndummy_recipe &lt;-\n  base_recipe |&gt;\n  step_dummy(all_nominal_predictors())\n\n# Recipe for splines\nspline_recipe &lt;-\n  dummy_recipe |&gt;\n  step_bs(GrLivArea)\n```\n\n\n\nSetting Models Specifications\n\n```{r}\n#| label: ModelsSpecs\n#| code-fold: false\n\n# install.packages(c(\"ranger\", \"ëarth\"))\n\n# Model 1 Setup\nspec_lm &lt;- \n  linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  set_mode(\"regression\")\n\n# Model 2\nspec_rf &lt;-\n  rand_forest(trees = 1000) |&gt;\n  set_engine(\"ranger\") |&gt;\n  set_mode(\"regression\")\n  \n# Model 3\nspec_mars &lt;-\n  mars() |&gt;\n  set_engine(\"earth\") |&gt;\n  set_mode(\"regression\")\n```\n\n\n\nDefining a workflow set\nWith a workflow set I can combine a list of pre-processors with a list of models:\n\n\nCode\n```{r}\n# Workflow set\n\n# Allows combine different pre-processors and models fit them all at once and compare results\n\nlist_of_recipes &lt;- list(base_recipe, dummy_recipe, spline_recipe)\nlist_of_models &lt;- list(spec_rf, spec_mars, spec_lm)\n\names_set &lt;- \n  workflow_set(\n    list_of_recipes, \n    list_of_models, \n    cross = FALSE, \n    case_weights = NULL)\n\names_set\n```\n\n\n# A tibble: 3 × 4\n  wflow_id             info             option    result    \n  &lt;chr&gt;                &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 recipe_1_rand_forest &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 recipe_2_mars        &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n3 recipe_3_linear_reg  &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n\n\n\n\nTraining with the Bootstrap samples\n\n\nCode\n```{r}\n#| label: GoF\n\n# install.packages(\"doParallel\")\n\n# doParallel::registerDoParallel()\n# set.seed(1982)\n\n# ames_results &lt;- workflow_map(ames_set, \"fit_resamples\", resamples = ames_boots)\n# ames_results\n\n# save(ames_results, file = \"./models/ames_results_wf.Rdata\")\n\n# ames_results &lt;- load(\"./models/ames_results_wf.Rdata\")\n```\n\n\n\n\nEvaluating the workflow\n\n\nCode\n```{r}\n#| label: EvaluateResults\n\n# plt_res &lt;- workflowsets::autoplot(ames_results)\n\n# plt_res\n```\n\n\n\n\nCode\n```{r}\n# ames_wf &lt;- workflow() |&gt;\n#   add_model(spec_lm) |&gt;\n#   add_formula(SalePrice ~ GrLivArea)\n\n# # Fit models to bootstrapped sets\n\n# trained_models &lt;- fit_resamples(object = ames_wf, resamples = ames_boots)\n\n# # See estimated performance\n# trained_models |&gt;  collect_metrics(summarize = TRUE) # TRUE gets Avg. performance \n```"
  }
]